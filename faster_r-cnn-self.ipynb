{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载必备库文件\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet import init\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了便于参数导入，变量名最好和 gluoncv 的变量名相同\n",
    "class BottleneckV1b(gluon.HybridBlock):\n",
    "    \"\"\"res 基本模块\"\"\"\n",
    "    def __init__(self, channels, strides, isdownsample=False, **kwargs):\n",
    "        super(BottleneckV1b, self).__init__(**kwargs)\n",
    "        # 一个 bottleneck 内， 1*1 卷积 channel 扩大的倍数\n",
    "        self.expansion = 4\n",
    "        self.isdownsample = isdownsample\n",
    "        self.strides = strides\n",
    "\n",
    "        \n",
    "        # bottletneck 内总是 1*1 conv -- 3*3 conv -- 1*1 conv\n",
    "        self.conv1 = nn.Conv2D(channels=channels, kernel_size=(1,1), strides=(1,1),\n",
    "                               padding=(0,0), groups=1, use_bias=False)\n",
    "        self.bn1   = nn.BatchNorm() # use_global_stats=True 默认为 False\n",
    "        self.relu  = nn.Activation('relu')\n",
    "        \n",
    "        self.conv2 = nn.Conv2D(channels=channels, kernel_size=3, strides=self.strides,\n",
    "                               padding=(1,1), groups=1, use_bias=False)\n",
    "        self.bn2   = nn.BatchNorm()\n",
    "        \n",
    "        self.conv3 = nn.Conv2D(channels=channels * self.expansion, kernel_size=(1,1), strides=(1,1),\n",
    "                               padding=(0,0), groups=1, use_bias=False)\n",
    "        self.bn3   = nn.BatchNorm()\n",
    "        \n",
    "        if self.isdownsample:\n",
    "            self.downsample = nn.HybridSequential()\n",
    "            self.downsample.add(nn.Conv2D(channels=channels * self.expansion, kernel_size=(1,1), strides=self.strides,\n",
    "                                         padding=(0,0), groups=1, use_bias=False),\n",
    "                                nn.BatchNorm())\n",
    "\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = self.relu(self.bn1(self.conv1(x)))\n",
    "        residual = self.relu(self.bn2(self.conv2(residual)))\n",
    "        residual = self.bn3(self.conv3(residual))\n",
    "\n",
    "        if self.isdownsample:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        x = x + residual\n",
    "        out = self.relu(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(gluon.HybridBlock):\n",
    "    \"\"\" Pre-trained ResNetV1b Model, which produces the strides of 8\n",
    "    featuremaps at conv5.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    block_nums : list of int\n",
    "        ResNet 每个 block 重复的次数\n",
    "    channels : list of int\n",
    "        每个 block 内卷积的 channel\n",
    "    strides : list\n",
    "        每个 block 的残差结构中 3*3 卷积的滑动步长 stride\n",
    "    classes : int, default 1000\n",
    "        目标类别的个数\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block_nums, channels, strides, classes=1000, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "\n",
    "        self.features = nn.HybridSequential()\n",
    "        self.features.add(nn.Conv2D(channels=64, kernel_size=(7,7), strides=(2,2),\n",
    "                                    padding=(3,3), groups=1, use_bias=False))\n",
    "        self.features.add(nn.BatchNorm())\n",
    "        self.features.add(nn.Activation('relu'))\n",
    "        self.features.add(nn.MaxPool2D(pool_size=(3,3), strides=(2,2), padding=(1,1)))\n",
    "        \n",
    "        # block_nums = [3, 4, 6, 3]\n",
    "        # channels = [64, 128, 256, 512]\n",
    "        # strides = [(1,1), (2,2), (2,2), (2,2)]\n",
    "        for i in range(len(block_nums)):\n",
    "            blk = nn.HybridSequential()\n",
    "            for num in range(block_nums[i]) :\n",
    "                if num == 0:\n",
    "                    bottleneck = BottleneckV1b(channels[i], strides[i], isdownsample=True)\n",
    "                else:\n",
    "                    bottleneck = BottleneckV1b(channels[i], (1,1), isdownsample=False)\n",
    "                blk.add(bottleneck)\n",
    "            self.features.add(blk)\n",
    "\n",
    "        self.avgpool = nn.GlobalAvgPool2D()\n",
    "        self.out = nn.Dense(classes)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        feature = self.features(x)\n",
    "        out = self.avgpool(feature)\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "res18_blk_num  = [2, 2, 2,  2] # 不是 bottleneck\n",
    "res50_blk_num  = [3, 4, 6,  3]\n",
    "res101_blk_num = [3, 4, 23, 3]\n",
    "res152_blk_num = [3, 8, 36, 3]\n",
    "\n",
    "block_nums = [3, 4, 6, 3]\n",
    "channels = [64, 128, 256, 512]\n",
    "strides = [(1,1), (2,2), (2,2), (2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet(block_nums, channels, strides)\n",
    "x = nd.random.uniform(shape=(1,1,224,224))\n",
    "net.initialize(init.Xavier())\n",
    "y = net(x)\n",
    "#print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(bbox_a, bbox_b):\n",
    "    \"\"\"计算两组 bounding boxes 的 Intersection-Over-Union(IOU)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bbox_a : numpy.ndarray\n",
    "        shape (M, 4) . bbox 格式 (xmin,ymin,xmax,ymax)\n",
    "    bbox_b : numpy.ndarray\n",
    "        shape (N, 4) . bbox 格式 (xmin,ymin,xmax,ymax)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    二维数组 shape (M,N) ，其中任意一个元素 (i,j) 表示 bboxa[i] 和 bboxb[j] 的 IoU\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if bbox_a.shape[1] < 4 or bbox_b.shape[1] < 4:\n",
    "        raise IndexError(\"Bounding boxes axis 1 must have at least length 4\")\n",
    "\n",
    "    tl = np.maximum(bbox_a[:, None, :2], bbox_b[:, :2])\n",
    "    br = np.minimum(bbox_a[:, None, 2:4], bbox_b[:, 2:4])\n",
    "\n",
    "    area_i = np.prod(br - tl, axis=2) * (tl < br).all(axis=2)\n",
    "    area_a = np.prod(bbox_a[:, 2:4] - bbox_a[:, :2], axis=1)\n",
    "    area_b = np.prod(bbox_b[:, 2:4] - bbox_b[:, :2], axis=1)\n",
    "    return area_i / (area_a[:, None] + area_b - area_i)\n",
    "\n",
    "\n",
    "# 依据 score 排序，从 score 最高第一个 box 开始，所有与该 box IOU 大于指定阈值的\n",
    "# box 都会被删掉；同时把 box 加入到最终的队列中，并从原 list 中删除。\n",
    "# 接着用队列中剩下的 score 最高的 box 去抑制队列中剩余的 box\n",
    "\n",
    "# 可以先删掉 score 比较低的 box\n",
    "def non_max_suppression(boxes, scores, threshold=0.7, topk=None):\n",
    "    \"\"\"执行 non-maximum suppression ，返回保留 boxes 的索引.\n",
    "    boxes: [N, (y1, x1, y2, x2)]\n",
    "    scores: 1-D array of box scores.\n",
    "    threshold: Float. IoU 阈值，一般为 0.7\n",
    "    \"\"\"\n",
    "    assert boxes.shape[0] > 0\n",
    "    if boxes.dtype.kind != \"f\":\n",
    "        boxes = boxes.astype(np.float32)\n",
    "    print(\"nms bbox shape\", boxes.shape)\n",
    "    print(\"nms scores shape\", scores.shape)\n",
    "    #print(\"nms bbox\", boxes)\n",
    "    #print(\"nms scores\", scores)\n",
    "    \n",
    "\n",
    "    # scores 从大到小排序\n",
    "    ixs = scores.argsort()[::-1]\n",
    "    if topk:\n",
    "        ixs = ixs[:topk]\n",
    "    #print(\"nms ixs\", ixs)\n",
    "\n",
    "    pick = []\n",
    "    while len(ixs) > 0:\n",
    "        # 每次都选择队列中 score 最高的 box ，加入最终结果，并用他抑制队列中剩余的 box\n",
    "        i = ixs[0]\n",
    "        pick.append(i)\n",
    "        # Compute IoU of the picked box with the rest\n",
    "        iou = compute_iou(boxes[i][np.newaxis,:], boxes[ixs[1:]])\n",
    "        # Identify boxes with IoU over the threshold. This\n",
    "        # returns indices into ixs[1:], so add 1 to get\n",
    "        # indices into ixs.\n",
    "        remove_ixs = np.where(iou > threshold)[1] + 1\n",
    "        #print(\"nms remove_ixs\", remove_ixs)\n",
    "        # Remove indices of the picked and overlapped boxes.\n",
    "        # 所有与 score 最高的 box IoU 大于阈值的 box 都从队列中移除\n",
    "        ixs = np.delete(ixs, remove_ixs)\n",
    "        ixs = np.delete(ixs, 0)\n",
    "    print(\"nms pick len \", len(pick))\n",
    "    return np.array(pick, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center2corner(bbox):\n",
    "    \"\"\" (x,y,w,h) --> (xmin,ymin,xmax,ymax) \n",
    "    shape: (N,4)\"\"\"\n",
    "    shift = bbox[:,2:] // 2\n",
    "    xymin = bbox[:,:2] - shift\n",
    "    xymax = bbox[:,:2] + shift\n",
    "    return np.concatenate((xymin,xymax), axis=-1)\n",
    "\n",
    "\n",
    "def corner2center(bbox):\n",
    "    \"\"\" (xmin,ymin,xmax,ymax) --> (x,y,w,h) \n",
    "    shape: (N,4) \"\"\"\n",
    "    xy = (bbox[:,2:] + bbox[:,:2]) // 2\n",
    "    wh = bbox[:,2:] - bbox[:,:2]\n",
    "    return np.concatenate((xy,wh), axis=-1)\n",
    "\n",
    "\n",
    "def get_realbbox(bbox_pred, anchors, wh_max=4.42, std = (1,1)):\n",
    "    \"\"\"根据 anchor 得到预测边框的真实值\n",
    "    bbox_pred, anchors 都是 numpy array 数据类型 (x, y, w, h) 形式，返回值同样，维度 (C,N,4)\"\"\"\n",
    "    xy = bbox_pred[:,:,:2] * std[0] * anchors[:,:,2:] + anchors[:,:,:2]\n",
    "    wh = anchors[:,:,2:] * np.minimum(np.exp(bbox_pred[:,:,2:] * std[1]), wh_max)\n",
    "    return np.concatenate((xy,wh), axis=-1)\n",
    "\n",
    "\n",
    "def bbox_clip_by_img(bbox, img):\n",
    "    \"\"\"bbox / 返回值 形式 (xmin,ymin,xmax,ymax) \n",
    "    维度 (N,4)\"\"\"\n",
    "    imgsize = img[-2:]\n",
    "    print(imgsize)\n",
    "    bbox[:,:2] = np.maximum(bbox[:,:2], 0)\n",
    "    bbox[:,:2] = np.minimum(bbox[:,:2], imgsize)\n",
    "    bbox[:,2:] = np.minimum(bbox[:,2:], imgsize)\n",
    "    bbox[:,2:] = np.maximum(bbox[:,2:], 0)\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_gen(ratios, scales, width, height, stride):\n",
    "    \"\"\"生成 anchor\n",
    "    return (x, y, w, h)\"\"\"\n",
    "    anchor = []\n",
    "    for s in scales:\n",
    "        for r in ratios:\n",
    "            w = s / np.sqrt(r)\n",
    "            w = np.round(w * 0.5)\n",
    "            h = s * np.sqrt(r)\n",
    "            h = np.round(h * 0.5)\n",
    "            anchor.append([-w, -h, w, h])\n",
    "            \n",
    "    anchor = np.array(anchor)\n",
    "\n",
    "    x = range(width)\n",
    "    y = range(height)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    \n",
    "    offsets = np.concatenate((x[:,:,np.newaxis], y[:,:,np.newaxis], x[:,:,np.newaxis], y[:,:,np.newaxis]), axis = -1)\n",
    "    offsets *= stride\n",
    "    #print(offsets.shape)\n",
    "    #print(offsets)\n",
    "    # 中心点需要向右下角偏移 stride // 2\n",
    "    offsets += stride // 2\n",
    "    #print(offsets)\n",
    "    \n",
    "    anchor = anchor.reshape(1, -1, 4) + offsets.reshape(-1,1,4)\n",
    "    anchor = anchor.reshape(-1, 4)\n",
    "    \n",
    "    anchor = bbox_clip_by_img(anchor, (width*stride, height*stride))\n",
    "    anchor = corner2center(anchor)\n",
    "    return anchor\n",
    "\n",
    "ratios = [0.5, 1, 2]\n",
    "scales = [32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anch = anchor_gen(ratios, scales, 20, 10, 16)\n",
    "print(anch.shape)\n",
    "print(anch[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_generate_anchors(16, 16, ratios, scales, (20,10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_size(roi, score, cids=None, min_size = 16):\n",
    "    # (xmin,ymin,xmax,ymax)\n",
    "    width  = roi[:,2] - roi[:,0]\n",
    "    height = roi[:,3] - roi[:,1]\n",
    "\n",
    "    invalid = (width < min_size) + (height < min_size)\n",
    "    invalidindex = np.where(invalid!=0)\n",
    "    score = np.delete(score, invalidindex)\n",
    "    if cids is not None:\n",
    "        cids = np.delete(cids, invalidindex)\n",
    "    roi = np.delete(roi, invalidindex, axis=0)\n",
    "    return cids, score, roi\n",
    "\n",
    "\n",
    "def proposal(anchor, score, bbox_pred, pre_nms, post_nms, img, nms_threshold=0.3):\n",
    "    \"\"\"\n",
    "    anchor , bbox_pred 都是 (x,y,w,h) 格式\n",
    "    返回值是 (xmin, ymin, xmax, ymax)\n",
    "    \"\"\"\n",
    "    #pre_nms  = 6000\n",
    "    #post_nms = 300\n",
    "    #min_size = 60\n",
    "\n",
    "    # 根据 anchor 得到 Bbox 的真实大小 。 入参/返回值： (x,y,w,h)\n",
    "    roi = get_realbbox(bbox_pred[None,:], anchor[None,:])\n",
    "    print(\"roi shape\", roi.shape)\n",
    "\n",
    "    # roi 不能超过图像的边界。入参/返回值： (xmin,ymin,xmax,ymax)\n",
    "    roi = bbox_clip_by_img(center2corner(np.squeeze(roi)), img)\n",
    "\n",
    "    # 移除小于 min_size 的 roi  参/返回值： (xmin,ymin,xmax,ymax)\n",
    "    _, score, roi = remove_small_size(roi, score)\n",
    "    \n",
    "    print(\"roi--after remove small size\", roi.shape)\n",
    "    print(\"scores--after remove small size\", score.shape)\n",
    "\n",
    "    # Non-maximum suppression 入参是 (xmin, ymin, xmax, ymax)\n",
    "    keepindex = non_max_suppression(roi, score, nms_threshold, pre_nms)\n",
    "    \n",
    "    print(\"proposal keepindex shape\", keepindex.shape)\n",
    "\n",
    "    # 仅仅保留 post_nms 个数的 boxes\n",
    "    if post_nms:\n",
    "        keepindex = keepindex[:post_nms]\n",
    "\n",
    "    print(\"proposal keepindex shape--after rpn nms\", keepindex.shape)\n",
    "\n",
    "    rpn_scores = score[keepindex]\n",
    "    rpn_bbox = roi[keepindex,:]\n",
    "\n",
    "    return rpn_scores, rpn_bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxoutput(scores, bbox):\n",
    "    \"\"\"每个框只选取概率最大的类别输出\n",
    "    scores (M,N) . M 是个数， N 是类别数\n",
    "    bbox   (M,N,4)\n",
    "    \"\"\"\n",
    "    print(\"socres.shape\", scores.shape)\n",
    "    print(\"bbox.shape\", bbox.shape)\n",
    "    \n",
    "    scores = np.where(scores > 0.01, scores, 0)\n",
    "\n",
    "    index = scores.argsort(axis=-1)\n",
    "    index = index[:,::-1] # 逆序\n",
    "    cid  = index[:,0].astype(np.int32)\n",
    "    #print(cids)\n",
    "\n",
    "    score = []\n",
    "    # len(index) == M\n",
    "    for i in range(len(index)):\n",
    "        score.append(scores[i,cid[i]])\n",
    "        if i == 0:\n",
    "            box = bbox[i,cid[i],:]\n",
    "        else:\n",
    "            box = np.row_stack([box, bbox[i,cid[i],:]])\n",
    "\n",
    "    score = np.array(score)\n",
    "    return cid, score, box\n",
    "\n",
    "def cleanoutput(cid, score, box, threhold=0.5):\n",
    "    \"\"\"去除概率小于阈值的预测\"\"\"\n",
    "\n",
    "    # cid   类别标号  (M,) -- 0,1,2,3...79\n",
    "    # score 类别概率  (M,) -- 0.98,0.73,....\n",
    "    # box   框       (M,4) -- (x1,y1,x2,y2)\n",
    "\n",
    "    # 删除概率小于阈值的方框\n",
    "    remove_ixs = np.where(score < threhold)[0]\n",
    "    #print(\"score\", score)\n",
    "    #print(\"remove_ixs\", remove_ixs)\n",
    "    print(\"box.shape\", box.shape)\n",
    "    clean_cid   = np.delete(cid, remove_ixs)\n",
    "    clean_score = np.delete(score, remove_ixs, axis=0)\n",
    "    clean_box   = np.delete(box, remove_ixs, axis=0)\n",
    "    \n",
    "    return clean_cid, clean_score, clean_box\n",
    "\n",
    "\n",
    "def  classify_ouput(cids, scores, bbox):\n",
    "    \"\"\"将输出按照类别分类，便于分类别进行 NMS\n",
    "    data : numpy array\n",
    "    \n",
    "    输出 list \n",
    "    \"\"\"\n",
    "    # 按照类别进行排序\n",
    "    index = cids.argsort()\n",
    "    cids = cids[index]\n",
    "    scores = scores[index]\n",
    "    bbox = bbox[index,:]\n",
    "    \n",
    "    split_index = []\n",
    "    clas = cids[0]\n",
    "    index = 0\n",
    "    for i in range(1, len(cids)):\n",
    "        index += 1\n",
    "        if clas != cids[i]:\n",
    "            split_index.append(index)\n",
    "            clas = cids[i]\n",
    "            \n",
    "    data = np.column_stack((cids, scores, bbox))\n",
    "\n",
    "    return np.split(data, split_index)\n",
    "\n",
    "\n",
    "def perclassnms(data, threshold=0.7):\n",
    "    \"\"\"将输出结果分类别进行 NMS ，输出处理后的结果\"\"\"\n",
    "    \n",
    "    output = []\n",
    "    for i in range(len(data)):\n",
    "        bbox = data[i][:,2:]\n",
    "        score = data[i][:,1]\n",
    "        keepindex = non_max_suppression(bbox, score, threshold)\n",
    "        if i == 0:\n",
    "            output = data[i][keepindex,:]\n",
    "        else:\n",
    "            output = np.row_stack([output,data[i][keepindex,:]])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsize = [600,600]\n",
    "class FasterRcnn(gluon.HybridBlock):\n",
    "    \"\"\"res50 为 bone 的 faster r-cnn\"\"\"\n",
    "    def __init__(self, class_num=80, **kwargs):\n",
    "        super(FasterRcnn, self).__init__(**kwargs)\n",
    "        self.img = imgsize\n",
    "        \n",
    "        # resnet50\n",
    "        self.block_nums = [3, 4, 6, 3]\n",
    "        self.channels = [64, 128, 256, 512]\n",
    "        self.strides = [(1,1), (2,2), (2,2), (2,2)]\n",
    "        \n",
    "        # gluoncv 中使用了 15 个 anchor\n",
    "        self.ratios = [0.5, 1, 2]\n",
    "        self.scales = [32, 64, 128, 256, 512]\n",
    "        self.anchor_depth = len(self.ratios) * len(self.scales)\n",
    "        self.rpn_channels = 1024\n",
    "        self.rpn_nms_threshold = 0.7\n",
    "        self.roi_size = (14, 14)\n",
    "        self.pre_nms = 6000\n",
    "        self.post_nms = 300\n",
    "        self.stride = 16\n",
    "\n",
    "        self.class_num = class_num \n",
    "        self.socre_thread = 0.01\n",
    "\n",
    "        # 网络的 bone\n",
    "        bone = ResNet(self.block_nums, self.channels, self.strides)\n",
    "        self.features = bone.features[:7]\n",
    "        self.top_features = bone.features[7:8]\n",
    "\n",
    "        # 输出预测网络\n",
    "        self.global_avg_pool = nn.GlobalAvgPool2D()\n",
    "        self.class_predictor = nn.Dense(self.class_num + 1)\n",
    "        self.box_predictor = nn.Dense(self.class_num * 4)\n",
    "\n",
    "        # RPN 网络\n",
    "        self.rpn = nn.HybridSequential()\n",
    "        self.rpn.add(nn.Conv2D(self.rpn_channels, 3, 1, 1))\n",
    "        self.rpn.add(nn.Activation('relu'))\n",
    "        # 使用了 sigmoid 而不是 softmax，减少通道的个数\n",
    "        self.rpn_score = nn.Conv2D(self.anchor_depth, 1, 1, 0)\n",
    "        self.rpn_loc = nn.Conv2D(self.anchor_depth * 4, 1, 1, 0)\n",
    "\n",
    "        \n",
    "    def hybrid_forward(self, F, x):\n",
    "        # 提取特征\n",
    "        feat   = self.features(x)\n",
    "        print(\"x\",x.shape)\n",
    "        print(\"feat\",feat.shape)\n",
    "        width  = feat.shape[2]\n",
    "        height = feat.shape[3]\n",
    "\n",
    "        # RPN\n",
    "        rpn = self.rpn(feat)\n",
    "        print(\"rpn conv3*3 shape\", rpn.shape)\n",
    "        raw_rpn_score = self.rpn_score(rpn).transpose(axes=(0, 2, 3, 1)).reshape((0, -1, 1))\n",
    "        rpn_score = nd.sigmoid(raw_rpn_score)\n",
    "        # rpn_box_pred -- (x,y,w,h)\n",
    "        rpn_box_pred = self.rpn_loc(rpn).transpose(axes=(0, 2, 3, 1)).reshape((0, -1, 4))\n",
    "        print(\"rpn_score shape\", rpn_score.shape)\n",
    "        print(\"rpn_box_pred shape\", rpn_box_pred.shape)\n",
    "        # 生成 anchor (x,y,w,h)\n",
    "        anchor = anchor_gen(self.ratios, self.scales, width, height, self.stride)\n",
    "        print(\"anchor\", anchor.shape)\n",
    "        # 入参/返回值全部是 numpy.array 。\n",
    "        # 入参 rpn_box_pred/anchor -- (x,y,w,h); 返回值 rpn_box -- (xmin,ymin,xmax,ymax)\n",
    "        rpn_score, rpn_box = proposal(anchor, np.squeeze(rpn_score.asnumpy()), np.squeeze(rpn_box_pred.asnumpy()), \n",
    "                                      self.pre_nms, self.post_nms, self.img, self.rpn_nms_threshold)\n",
    "        print(\"proposal--rpn_score shape\", rpn_score.shape)\n",
    "        print(\"proposal--rpn_box shape\", rpn_box.shape)\n",
    "\n",
    "        # roi 开始增加 batchid 0\n",
    "        rpn_box = rpn_box.reshape((-1, 4))\n",
    "        # tmp 作为返回值，画图检查 proposal 建议的前景框怎么样\n",
    "        plt_rpn_box = rpn_box\n",
    "        plt_rpn_score = rpn_score\n",
    "        roi_batchid = nd.zeros((min(rpn_box.shape[0], self.post_nms), 1))\n",
    "        rpn_box = nd.array(rpn_box)\n",
    "        rpn_roi = nd.concat(*[roi_batchid, rpn_box], dim=-1)        \n",
    "        # ROIPolling 入参 (xmin,ymin,xmax,ymax)\n",
    "        # 拿到这里的入参 rpn_roi 不需要除以 stride ，因为入参中有 stride 参数 TODO\n",
    "        pooled_feat = nd.ROIPooling(feat, rpn_roi, self.roi_size, 1. / self.stride)\n",
    "        print(\"pooled_feat shape\", pooled_feat.shape)\n",
    "\n",
    "        # RCNN prediction\n",
    "        top_feat = self.top_features(pooled_feat)\n",
    "        avg_feat = self.global_avg_pool(top_feat)\n",
    "        cls_pred = self.class_predictor(avg_feat)\n",
    "        box_pred = self.box_predictor(avg_feat)\n",
    "\n",
    "        cls_pred = cls_pred.reshape((self.post_nms, self.class_num + 1))\n",
    "        # 0 是背景的概率，只需要前景的即可 ; 不是说好了要使用 sigmoid 吗？ TODO\n",
    "        cls_pred = nd.softmax(cls_pred, axis=-1)[:,1:].asnumpy()\n",
    "        print(\"cls_pred shape\", cls_pred.shape)\n",
    "        #box_pred = box_pred.reshape((self.post_nms, self.class_num, 4)).transpose((1,0,2))\n",
    "        box_pred = box_pred.reshape((self.post_nms, self.class_num, 4)).asnumpy() # (x,y,w,h)\n",
    "        print(\"box_pred\", box_pred.shape)\n",
    "        \n",
    "        # 每个 box 只输出类别概率最大的\n",
    "        cids, scores, box_pred = maxoutput(cls_pred, box_pred)\n",
    "        print(\"cids shape\", cids.shape)\n",
    "        print(\"scores shape\", scores.shape)\n",
    "        print(\"box_pred\", box_pred.shape)\n",
    "        \n",
    "        # 将 rpn_box 从 (xmin,ymin,xmax,ymax) 转换到 (x,y,w,h)\n",
    "        rpn_box = corner2center(rpn_box.reshape(-1,4).asnumpy())\n",
    "        print(\"rpn_box\", rpn_box)\n",
    "        print(\"box_pred\", box_pred)\n",
    "        # 入参/返回值是 (x,y,w,h) 格式 ，且返回值维度 (C,N,4)\n",
    "        bbox = get_realbbox(box_pred.reshape(1,-1,4), rpn_box.reshape(1,-1,4), wh_max=4.42, std = (0.1,0.2))\n",
    "        print(\"bbox\", bbox.shape)\n",
    "        cids, scores, bbox = cleanoutput(cids, scores, np.squeeze(bbox))\n",
    "        # 入参/返回值都是 (xmin,ymin,xmax,ymax) 格式\n",
    "        bbox = bbox_clip_by_img(center2corner(bbox.reshape(-1,4)), img=imgsize)\n",
    "        #bbox = bbox.transpose((1,0,2))\n",
    "        # 入参/返回值都是 (xmin,ymin,xmax,ymax) 格式\n",
    "        cids, scores, bbox = remove_small_size(bbox, scores, cids, 1)\n",
    "        print(\"bbox\", bbox.shape)        \n",
    "\n",
    "        # 输出按照类别分组\n",
    "        data = classify_ouput(cids, scores, bbox)\n",
    "        #print(data)\n",
    "        plotoutput = perclassnms(data, 0.1)\n",
    "        #print(plotoutput)\n",
    "\n",
    "        bounding_boxs = plotoutput[:,2:]\n",
    "        scores = plotoutput[:,1]\n",
    "        class_IDs = plotoutput[:,0]\n",
    "        print(\"class_IDs\", class_IDs)\n",
    "        print(\"scores\", scores)\n",
    "        print(\"bbox\", bounding_boxs)\n",
    "\n",
    "        return bounding_boxs, scores, class_IDs, plt_rpn_box, plt_rpn_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FasterRcnn()\n",
    "\n",
    "# 加载参数\n",
    "net.features.load_parameters(\"features.params\")\n",
    "net.top_features.load_parameters(\"topfeatures.params\")\n",
    "#net.global_avg_pool.load_parameters(\"global_avg_pool.params\")\n",
    "net.class_predictor.load_parameters(\"class_predictor.params\")\n",
    "net.box_predictor.load_parameters(\"box_predictor.params\")\n",
    "net.rpn.load_parameters(\"rpn_conv1.params\")\n",
    "net.rpn_score.load_parameters(\"rpn_score.params\")\n",
    "net.rpn_loc.load_parameters(\"rpn_loc.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_img(imgname, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    \"\"\"图像 nominalize \n",
    "    测试的时候，transform 不需要额外的处理，只需要归一化以及将 BCWH -> \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs : string \n",
    "        待处理的图像名字\n",
    "    mean : iterable of float\n",
    "        imagenet mean\n",
    "    std : iterable of float\n",
    "        imagenet std\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    网络的输入和 resize 后的图像\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    img = mx.image.imread(imgname)\n",
    "\n",
    "    # 可能只能在 800*600 时 work\n",
    "    img = mx.image.imresize(img, imgsize[0], imgsize[1])\n",
    "    orig_img = img.asnumpy().astype('uint8')\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    img = mx.nd.image.normalize(img, mean=mean, std=std)\n",
    "    print(img.shape)\n",
    "    # img.expand_dims(0) 由 CHW -> BCHW\n",
    "    return img.expand_dims(0), orig_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "imgname = 'biking.jpg'\n",
    "\n",
    "imgname = '1.jpg'\n",
    "imgname = '2.jpg'\n",
    "imgname = '3.jpg'\n",
    "\n",
    "\n",
    "imgname = 'eagle.jpg'\n",
    "imgname = 'person.jpg'\n",
    "imgname = 'dog.jpg'\n",
    "\n",
    "x, img = preprocessing_img(imgname)\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coco 80 个类\n",
    "classes_name = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', \n",
    "                'train', 'truck', 'boat', 'traffic light', 'fire hydrant', \n",
    "                'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', \n",
    "                'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', \n",
    "                'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "                'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', \n",
    "                'baseball glove', 'skateboard', 'surfboard', 'tennis racket', \n",
    "                'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', \n",
    "                'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', \n",
    "                'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "                'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', \n",
    "                'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', \n",
    "                'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', \n",
    "                'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes_name[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from gluoncv import utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "bounding_boxs, scores, class_IDs, plt_rpn_box, plt_rpn_score = y\n",
    "\n",
    "ax = utils.viz.plot_bbox(img, bounding_boxs, scores,\n",
    "                         class_IDs, class_names=classes_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bounding_boxs.shape, class_IDs.shape, scores.shape)\n",
    "print(bounding_boxs, class_IDs, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3\n",
    "rpn_cls_id = np.zeros(num)\n",
    "ax = utils.viz.plot_bbox(img, plt_rpn_box[:num], plt_rpn_score[:num],\n",
    "                         rpn_cls_id[:num], class_names=classes_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv import model_zoo\n",
    "\n",
    "net = model_zoo.get_model('faster_rcnn_resnet50_v1b_coco', pretrained=True)\n",
    "\n",
    "net.features.save_parameters(\"features.params\")\n",
    "net.top_features.save_parameters(\"topfeatures.params\")\n",
    "#net.global_avg_pool.save_parameters(\"global_avg_pool.params\")\n",
    "net.class_predictor.save_parameters(\"class_predictor.params\")\n",
    "net.box_predictor.save_parameters(\"box_predictor.params\")\n",
    "net.rpn.conv1.save_parameters(\"rpn_conv1.params\")\n",
    "net.rpn.score.save_parameters(\"rpn_score.params\")\n",
    "net.rpn.loc.save_parameters(\"rpn_loc.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
