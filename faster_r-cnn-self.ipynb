{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载必备库文件\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet import init\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2D??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res18_blk_num  = [2, 2, 2,  2] # 不是 bottleneck\n",
    "res50_blk_num  = [3, 4, 6,  3]\n",
    "res101_blk_num = [3, 4, 23, 3]\n",
    "res152_blk_num = [3, 8, 36, 3]\n",
    "\n",
    "# 为了便于参数导入，变量名最好和 gluoncv 的变量名相同\n",
    "class BottleneckV1b(gluon.HybridBlock):\n",
    "    \"\"\"res 基本模块\"\"\"\n",
    "    def __init__(self, channels, strides, isdownsample=False, **kwargs):\n",
    "        super(BottleneckV1b, self).__init__(**kwargs)\n",
    "        # 一个 bottleneck 内， 1*1 卷积 channel 扩大的倍数\n",
    "        self.expansion = 4\n",
    "        self.isdownsample = isdownsample\n",
    "        self.strides = strides\n",
    "\n",
    "        \n",
    "        # bottletneck 内总是 1*1 conv -- 3*3 conv -- 1*1 conv\n",
    "        self.conv1 = nn.Conv2D(channels=channels, kernel_size=(1,1), strides=(1,1),\n",
    "                               padding=(0,0), groups=1, use_bias=False)\n",
    "        self.bn1   = nn.BatchNorm() # use_global_stats=True 默认为 False\n",
    "        self.relu  = nn.Activation('relu')\n",
    "        \n",
    "        self.conv2 = nn.Conv2D(channels=channels, kernel_size=3, strides=self.strides,\n",
    "                               padding=(1,1), groups=1, use_bias=False)\n",
    "        self.bn2   = nn.BatchNorm()\n",
    "        \n",
    "        self.conv3 = nn.Conv2D(channels=channels * self.expansion, kernel_size=(1,1), strides=(1,1),\n",
    "                               padding=(0,0), groups=1, use_bias=False)\n",
    "        self.bn3   = nn.BatchNorm()\n",
    "        \n",
    "        if self.isdownsample:\n",
    "            self.downsample = nn.HybridSequential()\n",
    "            self.downsample.add(nn.Conv2D(channels=channels * self.expansion, kernel_size=(1,1), strides=self.strides,\n",
    "                                         padding=(0,0), groups=1, use_bias=False),\n",
    "                                nn.BatchNorm())\n",
    "\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = self.relu(self.bn1(self.conv1(x)))\n",
    "        residual = self.relu(self.bn2(self.conv2(residual)))\n",
    "        residual = self.bn3(self.conv3(residual))\n",
    "\n",
    "        if self.isdownsample:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        x = x + residual\n",
    "        out = self.relu(x)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BottleneckV1b(64, (2,2), isdownsample=True)\n",
    "x = nd.random.uniform(shape=(1,1,224,224))\n",
    "net.initialize(init.Xavier())\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(gluon.HybridBlock):\n",
    "    \"\"\" Pre-trained ResNetV1b Model, which produces the strides of 8\n",
    "    featuremaps at conv5.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : Block\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    norm_layer : object\n",
    "        Normalization layer used (default: :class:`mxnet.gluon.nn.BatchNorm`)\n",
    "        Can be :class:`mxnet.gluon.nn.BatchNorm` or :class:`mxnet.gluon.contrib.nn.SyncBatchNorm`.\n",
    "    last_gamma : bool, default False\n",
    "        Whether to initialize the gamma of the last BatchNorm layer in each bottleneck to zero.\n",
    "    deep_stem : bool, default False\n",
    "        Whether to replace the 7x7 conv1 with 3 3x3 convolution layers.\n",
    "    avg_down : bool, default False\n",
    "        Whether to use average pooling for projection skip connection between stages/downsample.\n",
    "    final_drop : float, default 0.0\n",
    "        Dropout ratio before the final classification layer.\n",
    "    use_global_stats : bool, default False\n",
    "        Whether forcing BatchNorm to use global statistics instead of minibatch statistics;\n",
    "        optionally set to True if finetuning using ImageNet classification pretrained models.\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block_nums, channels, strides, classes=1000, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "\n",
    "        self.features = nn.HybridSequential()\n",
    "        self.features.add(nn.Conv2D(channels=64, kernel_size=(7,7), strides=(2,2),\n",
    "                                    padding=(3,3), groups=1, use_bias=False))\n",
    "        self.features.add(nn.BatchNorm())\n",
    "        self.features.add(nn.Activation('relu'))\n",
    "        self.features.add(nn.MaxPool2D(pool_size=(3,3), strides=(2,2), padding=(1,1)))\n",
    "        \n",
    "        # block_nums = [3, 4, 6, 3]\n",
    "        # channels = [64, 128, 256, 512]\n",
    "        # strides = [(1,1), (2,2), (2,2), (2,2)]\n",
    "        for i in range(len(block_nums)):\n",
    "            blk = nn.HybridSequential()\n",
    "            for num in range(block_nums[i]) :\n",
    "                if num == 0:\n",
    "                    bottleneck = BottleneckV1b(channels[i], strides[i], isdownsample=True)\n",
    "                else:\n",
    "                    bottleneck = BottleneckV1b(channels[i], (1,1), isdownsample=False)\n",
    "                blk.add(bottleneck)\n",
    "            self.features.add(blk)\n",
    "\n",
    "        self.avgpool = nn.GlobalAvgPool2D()\n",
    "        self.out = nn.Dense(classes)\n",
    "\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        feature = self.features(x)\n",
    "        out = self.avgpool(feature)\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "\n",
    "block_nums = [3, 4, 6, 3]\n",
    "channels = [64, 128, 256, 512]\n",
    "strides = [(1,1), (2,2), (2,2), (2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet(block_nums, channels, strides)\n",
    "x = nd.random.uniform(shape=(1,1,224,224))\n",
    "net.initialize(init.Xavier())\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
