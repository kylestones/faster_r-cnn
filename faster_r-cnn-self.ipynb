{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载必备库文件\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet import init\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res18_blk_num  = [2, 2, 2,  2] # 不是 bottleneck\n",
    "res50_blk_num  = [3, 4, 6,  3]\n",
    "res101_blk_num = [3, 4, 23, 3]\n",
    "res152_blk_num = [3, 8, 36, 3]\n",
    "\n",
    "# 为了便于参数导入，变量名最好和 gluoncv 的变量名相同\n",
    "class BottleneckV1b(gluon.HybridBlock):\n",
    "    \"\"\"res 基本模块\"\"\"\n",
    "    def __init__(self, channels, strides, isdownsample=False, **kwargs):\n",
    "        super(BottleneckV1b, self).__init__(**kwargs)\n",
    "        # 一个 bottleneck 内， 1*1 卷积 channel 扩大的倍数\n",
    "        self.expansion = 4\n",
    "        self.isdownsample = isdownsample\n",
    "        self.strides = strides\n",
    "\n",
    "        \n",
    "        # bottletneck 内总是 1*1 conv -- 3*3 conv -- 1*1 conv\n",
    "        self.conv1 = nn.Conv2D(channels=channels, kernel_size=(1,1), strides=(1,1),\n",
    "                               padding=(0,0), groups=1, use_bias=False)\n",
    "        self.bn1   = nn.BatchNorm() # use_global_stats=True 默认为 False\n",
    "        self.relu  = nn.Activation('relu')\n",
    "        \n",
    "        self.conv2 = nn.Conv2D(channels=channels, kernel_size=3, strides=self.strides,\n",
    "                               padding=(1,1), groups=1, use_bias=False)\n",
    "        self.bn2   = nn.BatchNorm()\n",
    "        \n",
    "        self.conv3 = nn.Conv2D(channels=channels * self.expansion, kernel_size=(1,1), strides=(1,1),\n",
    "                               padding=(0,0), groups=1, use_bias=False)\n",
    "        self.bn3   = nn.BatchNorm()\n",
    "        \n",
    "        if self.isdownsample:\n",
    "            self.downsample = nn.HybridSequential()\n",
    "            self.downsample.add(nn.Conv2D(channels=channels * self.expansion, kernel_size=(1,1), strides=self.strides,\n",
    "                                         padding=(0,0), groups=1, use_bias=False),\n",
    "                                nn.BatchNorm())\n",
    "\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = self.relu(self.bn1(self.conv1(x)))\n",
    "        residual = self.relu(self.bn2(self.conv2(residual)))\n",
    "        residual = self.bn3(self.conv3(residual))\n",
    "\n",
    "        if self.isdownsample:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        x = x + residual\n",
    "        out = self.relu(x)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(gluon.HybridBlock):\n",
    "    \"\"\" Pre-trained ResNetV1b Model, which produces the strides of 8\n",
    "    featuremaps at conv5.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : Block\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    norm_layer : object\n",
    "        Normalization layer used (default: :class:`mxnet.gluon.nn.BatchNorm`)\n",
    "        Can be :class:`mxnet.gluon.nn.BatchNorm` or :class:`mxnet.gluon.contrib.nn.SyncBatchNorm`.\n",
    "    last_gamma : bool, default False\n",
    "        Whether to initialize the gamma of the last BatchNorm layer in each bottleneck to zero.\n",
    "    deep_stem : bool, default False\n",
    "        Whether to replace the 7x7 conv1 with 3 3x3 convolution layers.\n",
    "    avg_down : bool, default False\n",
    "        Whether to use average pooling for projection skip connection between stages/downsample.\n",
    "    final_drop : float, default 0.0\n",
    "        Dropout ratio before the final classification layer.\n",
    "    use_global_stats : bool, default False\n",
    "        Whether forcing BatchNorm to use global statistics instead of minibatch statistics;\n",
    "        optionally set to True if finetuning using ImageNet classification pretrained models.\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block_nums, channels, strides, classes=1000, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "\n",
    "        self.features = nn.HybridSequential()\n",
    "        self.features.add(nn.Conv2D(channels=64, kernel_size=(7,7), strides=(2,2),\n",
    "                                    padding=(3,3), groups=1, use_bias=False))\n",
    "        self.features.add(nn.BatchNorm())\n",
    "        self.features.add(nn.Activation('relu'))\n",
    "        self.features.add(nn.MaxPool2D(pool_size=(3,3), strides=(2,2), padding=(1,1)))\n",
    "        \n",
    "        # block_nums = [3, 4, 6, 3]\n",
    "        # channels = [64, 128, 256, 512]\n",
    "        # strides = [(1,1), (2,2), (2,2), (2,2)]\n",
    "        for i in range(len(block_nums)):\n",
    "            blk = nn.HybridSequential()\n",
    "            for num in range(block_nums[i]) :\n",
    "                if num == 0:\n",
    "                    bottleneck = BottleneckV1b(channels[i], strides[i], isdownsample=True)\n",
    "                else:\n",
    "                    bottleneck = BottleneckV1b(channels[i], (1,1), isdownsample=False)\n",
    "                blk.add(bottleneck)\n",
    "            self.features.add(blk)\n",
    "\n",
    "        self.avgpool = nn.GlobalAvgPool2D()\n",
    "        self.out = nn.Dense(classes)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        feature = self.features(x)\n",
    "        out = self.avgpool(feature)\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "\n",
    "block_nums = [3, 4, 6, 3]\n",
    "channels = [64, 128, 256, 512]\n",
    "strides = [(1,1), (2,2), (2,2), (2,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet(block_nums, channels, strides)\n",
    "x = nd.random.uniform(shape=(1,1,224,224))\n",
    "net.initialize(init.Xavier())\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(bbox_a, bbox_b):\n",
    "    \"\"\"计算两组 bounding boxes 的 Intersection-Over-Union(IOU)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bbox_a : numpy.ndarray\n",
    "        shape (M, 4) . bbox 格式 (xmin,ymin,xmax,ymax)\n",
    "    bbox_b : numpy.ndarray\n",
    "        shape (N, 4) . bbox 格式 (xmin,ymin,xmax,ymax)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    二维数组 shape (M,N) ，其中任意一个元素 (i,j) 表示 bboxa[i] 和 bboxb[j] 的 IoU\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if bbox_a.shape[1] < 4 or bbox_b.shape[1] < 4:\n",
    "        raise IndexError(\"Bounding boxes axis 1 must have at least length 4\")\n",
    "\n",
    "    tl = np.maximum(bbox_a[:, None, :2], bbox_b[:, :2])\n",
    "    br = np.minimum(bbox_a[:, None, 2:4], bbox_b[:, 2:4])\n",
    "\n",
    "    area_i = np.prod(br - tl, axis=2) * (tl < br).all(axis=2)\n",
    "    area_a = np.prod(bbox_a[:, 2:4] - bbox_a[:, :2], axis=1)\n",
    "    area_b = np.prod(bbox_b[:, 2:4] - bbox_b[:, :2], axis=1)\n",
    "    return area_i / (area_a[:, None] + area_b - area_i)\n",
    "\n",
    "\n",
    "# 依据 score 排序，从 score 最高第一个 box 开始，所有与该 box IOU 大于指定阈值的\n",
    "# box 都会被删掉；同时把 box 加入到最终的队列中，并从原 list 中删除。\n",
    "# 接着用队列中剩下的 score 最高的 box 去抑制队列中剩余的 box\n",
    "\n",
    "# 可以先删掉 score 比较低的 box\n",
    "def non_max_suppression(boxes, scores, topk=None, threshold=0.7):\n",
    "    \"\"\"执行 non-maximum suppression ，返回保留 boxes 的索引.\n",
    "    boxes: [N, (y1, x1, y2, x2)]\n",
    "    scores: 1-D array of box scores.\n",
    "    threshold: Float. IoU 阈值，一般为 0.7\n",
    "    \"\"\"\n",
    "    assert boxes.shape[0] > 0\n",
    "    if boxes.dtype.kind != \"f\":\n",
    "        boxes = boxes.astype(np.float32)\n",
    "\n",
    "    # scores 从大到小排序\n",
    "    ixs = scores.argsort()[::-1]\n",
    "    if topk:\n",
    "        ixs = ixs[:topk]\n",
    "    #print(\"ixs\", ixs)\n",
    "\n",
    "    pick = []\n",
    "    while len(ixs) > 0:\n",
    "        # 每次都选择队列中 score 最高的 box ，加入最终结果，并用他抑制队列中剩余的 box\n",
    "        i = ixs[0]\n",
    "        pick.append(i)\n",
    "        # Compute IoU of the picked box with the rest\n",
    "        iou = compute_iou(boxes[i][np.newaxis,:], boxes[ixs[1:]])\n",
    "        # Identify boxes with IoU over the threshold. This\n",
    "        # returns indices into ixs[1:], so add 1 to get\n",
    "        # indices into ixs.\n",
    "        remove_ixs = np.where(iou > threshold)[1] + 1\n",
    "        #print(\"remove_ixs\", remove_ixs)\n",
    "        # Remove indices of the picked and overlapped boxes.\n",
    "        # 所有与 score 最高的 box IoU 大于阈值的 box 都从队列中移除\n",
    "        ixs = np.delete(ixs, remove_ixs)\n",
    "        ixs = np.delete(ixs, 0)\n",
    "    #print(\"pick\",pick)\n",
    "    return np.array(pick, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_gen(ratios, scales, width, height, stride):\n",
    "    \"\"\"生成 anchor\n",
    "    return (xmin, ymin, xmax, ymax)\"\"\"\n",
    "    anchor = []\n",
    "    for s in scales:\n",
    "        for r in ratios:\n",
    "            w = s / np.sqrt(r)\n",
    "            w = np.round(w * 0.5)\n",
    "            h = s * np.sqrt(r)\n",
    "            h = np.round(h * 0.5)\n",
    "            anchor.append([-w, -h, w, h])\n",
    "            \n",
    "    anchor = np.array(anchor)\n",
    "\n",
    "    x = range(width)\n",
    "    y = range(height)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    \n",
    "    offsets = np.concatenate((x[:,:,np.newaxis], y[:,:,np.newaxis], x[:,:,np.newaxis], y[:,:,np.newaxis]), axis = -1)\n",
    "    offsets *= stride\n",
    "    #print(offsets.shape)\n",
    "    #print(offsets)\n",
    "    # 中心点需要向右下角偏移 stride // 2\n",
    "    offsets += stride // 2\n",
    "    #print(offsets)\n",
    "    \n",
    "    anchor = anchor.reshape(1, -1, 4) + offsets.reshape(-1,1,4)\n",
    "    anchor = anchor.reshape(-1, 4)\n",
    "    \n",
    "    return anchor\n",
    "\n",
    "ratios = [0.5, 1, 2]\n",
    "scales = [32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = anchor_gen(ratios, scales, 600//16, 800//16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(16).reshape(2,2,4) * 0.1\n",
    "b = np.arange(8).reshape(1,2,4) * 0.3\n",
    "print(a)\n",
    "print(b)\n",
    "get_realbbox(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_realbbox(bbox_pred, anchors, wh_max=4.42):\n",
    "    \"\"\"根据 anchor 得到预测边框的真实值\n",
    "    bbox_pred, anchors 都是 numpy array 数据类型 (x, y, w, h) 形式，维度 (C,N,4)\"\"\"\n",
    "\n",
    "    xy = bbox_pred[:,:,:2] * anchors[:,:,2:] + anchors[:,:,:2]\n",
    "    wh = anchors[:,:,2:] * np.minimum(np.exp(bbox_pred[:,:,2:]), wh_max)\n",
    "    return np.concatenate((xy,wh), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(1,36,3).reshape(-1,4)\n",
    "b = np.arange(8,32,2).reshape(-1,4)\n",
    "print(a)\n",
    "print(b)\n",
    "get_realbbox(a[None,:],b[None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center2corner(bbox):\n",
    "    \"\"\" (x,y,w,h) --> (xmin,ymin,xmax,ymax) \n",
    "    shape: (N,4)\"\"\"\n",
    "    shift = bbox[:,2:] // 2\n",
    "    xymin = bbox[:,:2] - shift\n",
    "    xymax = bbox[:,:2] + shift\n",
    "    return np.concatenate((xymin,xymax), axis=-1)\n",
    "\n",
    "\n",
    "def corner2center(bbox):\n",
    "    \"\"\" (xmin,ymin,xmax,ymax) --> (x,y,w,h) \n",
    "    shape: (N,4) \"\"\"\n",
    "    xy = (bbox[:,2:] + bbox[:,:2]) // 2\n",
    "    wh = bbox[:,2:] - bbox[:,:2]\n",
    "    return np.concatenate((xy,wh), axis=-1)\n",
    "\n",
    "\n",
    "def get_realbbox(bbox_pred, anchors, wh_max=4.42):\n",
    "    \"\"\"根据 anchor 得到预测边框的真实值\n",
    "    bbox_pred, anchors 都是 numpy array 数据类型 (x, y, w, h) 形式，返回值同样，维度 (C,N,4)\"\"\"\n",
    "    xy = bbox_pred[:,:,:2] * anchors[:,:,2:] + anchors[:,:,:2]\n",
    "    wh = anchors[:,:,2:] * np.minimum(np.exp(bbox_pred[:,:,2:]), wh_max)\n",
    "    return np.concatenate((xy,wh), axis=-1)\n",
    "\n",
    "\n",
    "def bbox_clip_by_img(bbox, img):\n",
    "    \"\"\"bbox / 返回值 形式 (xmin,ymin,xmax,ymax) \n",
    "    维度 (N,4)\"\"\"\n",
    "    imgsize = img[-2:]\n",
    "    print(imgsize)\n",
    "    bbox[:,:2] = np.maximum(bbox[:,:2], 0)\n",
    "    bbox[:,2:] = np.minimum(bbox[:,2:], imgsize)\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal(anchor, score, bbox_pred, post_nms=300, img=[800,600], nms_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Generate proposals. Limit to batch-size=1 in current implementation.\n",
    "    img = [600,800]\n",
    "    \"\"\"\n",
    "    pre_nms  = 6000\n",
    "    #post_nms = 300\n",
    "    min_size = 60\n",
    "\n",
    "    # 根据 anchor 得到 Bbox 的真实大小 。 入参/返回值： (x,y,w,h)\n",
    "    roi = get_realbbox(bbox_pred[None,:], corner2center(anchor)[None,:])\n",
    "    print(\"roi\", roi.shape)\n",
    "\n",
    "    # roi 不能超过图像的边界。入参/返回值： (xmin,ymin,xmax,ymax)\n",
    "    roi = bbox_clip_by_img(center2corner(np.squeeze(roi)), img)\n",
    "\n",
    "    # remove bounding boxes that don't meet the min_size constraint\n",
    "    width  = roi[:,2] - roi[:,0]\n",
    "    height = roi[:,3] - roi[:,1]\n",
    "    print(\"width\", width)\n",
    "    print(\"height\", height)\n",
    "    invalid = (width < min_size) + (height < min_size)\n",
    "    print(\"invalid\", invalid)\n",
    "    print(\"scores\", score.shape)\n",
    "    invalidindex = np.where(invalid!=0)\n",
    "    score = np.delete(score, invalidindex)\n",
    "    print(\"scores\", score.shape)\n",
    "    print(\"roi\", roi.shape)\n",
    "    roi = np.delete(roi, invalidindex, axis=0)\n",
    "    \n",
    "    print(\"roi\", roi.shape)\n",
    "    print(\"scores\", score.shape)\n",
    "\n",
    "    # Non-maximum suppression\n",
    "    keepindex = non_max_suppression(roi, score, pre_nms, nms_threshold)\n",
    "    \n",
    "    print(\"keepindex\", keepindex.shape)\n",
    "\n",
    "    # 仅仅保留 post_nms 个数的 boxes\n",
    "    if post_nms:\n",
    "        keepindex = keepindex[:post_nms]\n",
    "\n",
    "    print(\"keepindex\", keepindex.shape)\n",
    "\n",
    "    rpn_scores = score[keepindex]\n",
    "    rpn_bbox = roi[keepindex,:]\n",
    "\n",
    "    return rpn_scores, rpn_bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = np.array([[-23., -11.,  23.,  11.],                   \n",
    "                [-16., -16.,  16.,  16.],\n",
    "                [-11., -23.,  11.,  23.],\n",
    "                [-21., -11.,  25.,  11.],\n",
    "                [-14., -16.,  18.,  16.],\n",
    "                [ -9., -23.,  13.,  23.],\n",
    "                [-23.,  -9.,  23.,  13.],\n",
    "                [-16., -14.,  16.,  18.],\n",
    "                [-11., -21.,  11.,  25.],\n",
    "                [-21.,  -9.,  25.,  13.],\n",
    "                [-14., -14.,  18.,  18.],\n",
    "                [ -9., -21.,  13.,  25.]])\n",
    "print(anchor.shape)\n",
    "score = np.array([0.8,0.2,0.4, 0.1,0.45,0.23, 0.45,0.21,0.93, 0.34,0.45,0.42])\n",
    "print(score.shape)\n",
    "bbox_pred = anchor + [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal(anchor, score, bbox_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bbox_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasterRcnn(gluon.HybridBlock):\n",
    "    \"\"\"res50 为 bone 的 faster r-cnn\"\"\"\n",
    "    def __init__(self, class_num=80, **kwargs):\n",
    "        super(FasterRcnn, self).__init__(**kwargs)        \n",
    "        \n",
    "        self.ratios = [0.5, 1, 2]\n",
    "        self.scales = [32, 64, 128, 256, 512]\n",
    "        self.anchor_depth = len(self.ratios) * len(self.scales) # gluoncv 中使用了 15 个 anchor\n",
    "        self.rpn_channels = 1024\n",
    "        self.roi_size = (14, 14)\n",
    "        self.post_nms = 50 #300\n",
    "        self.stride = 16\n",
    "        \n",
    "        self.class_num = class_num\n",
    "        \n",
    "        self.socre_thread = 0.01\n",
    "        \n",
    "        # 网络的 bone\n",
    "        bone = ResNet(block_nums, channels, strides)\n",
    "        #self.features = nn.HybridSequential()\n",
    "        #self.features.add(bone.features[:7])\n",
    "        self.features =bone.features[:7]\n",
    "        #self.top_features = nn.HybridSequential()\n",
    "        #self.top_features.add(bone.features[7:])\n",
    "        self.top_features = bone.features[7:]\n",
    "        \n",
    "        self.global_avg_pool = nn.GlobalAvgPool2D()\n",
    "        self.class_predictor = nn.Dense(self.class_num + 1)\n",
    "        self.box_predictor = nn.Dense(self.class_num * 4)\n",
    "        \n",
    "        # RPN 网络\n",
    "        self.rpn = nn.HybridSequential()\n",
    "        self.rpn.add(nn.Conv2D(self.rpn_channels, 3, 1, 1))\n",
    "        self.rpn.add(nn.Activation('relu'))\n",
    "        # 使用了 sigmoid 而不是 softmax，减少通道的个数\n",
    "        self.rpn_score = nn.Conv2D(self.anchor_depth, 1, 1, 0)\n",
    "        self.rpn_loc = nn.Conv2D(self.anchor_depth * 4, 1, 1, 0)\n",
    "\n",
    "        \n",
    "    def hybrid_forward(self, F, x):\n",
    "        feat = self.features(x)\n",
    "        print(\"feat\",feat.shape)\n",
    "        width = feat.shape[2] # 50\n",
    "        height = feat.shape[3] #38\n",
    "        \n",
    "        # RPN\n",
    "        anchor = anchor_gen(self.ratios, self.scales, width, height, self.stride)\n",
    "        print(\"anchor\", anchor.shape)\n",
    "        rpn = self.rpn(feat)\n",
    "        print(\"rpn\", rpn.shape)\n",
    "        raw_rpn_score = self.rpn_score(rpn).transpose(axes=(0, 2, 3, 1)).reshape((0, -1, 1))\n",
    "        rpn_score = nd.sigmoid(raw_rpn_score)\n",
    "        rpn_box_pred = self.rpn_loc(rpn).transpose(axes=(0, 2, 3, 1)).reshape((0, -1, 4))\n",
    "        print(\"rpn_score\", rpn_score.shape)\n",
    "        print(\"rpn_box_pred\", rpn_box_pred.shape)\n",
    "        # 入参/返回值全部是 numpy.array\n",
    "        rpn_score, rpn_box = proposal(anchor, rpn_score.asnumpy(), np.squeeze(rpn_box_pred.asnumpy()), \n",
    "                                      self.post_nms, img=[800,600], nms_threshold=0.3)\n",
    "        rpn_score = nd.array(rpn_score)\n",
    "        rpn_box = nd.array(rpn_box)\n",
    "        \n",
    "        # roi 开始增加 batchid 0\n",
    "        rpn_box = rpn_box.reshape((-1, 4))\n",
    "        roi_batchid = nd.zeros((self.post_nms, 1))\n",
    "        #roi_batchid = nd.zeros((rpn_box.shape[0], 1))\n",
    "        rpn_roi = nd.concat(*[roi_batchid.reshape((-1, 1)), rpn_box], dim=-1)\n",
    "        \n",
    "        # ROIPolling 入参 (xmin,ymin,xmax,ymax)\n",
    "        pooled_feat = nd.ROIPooling(feat, rpn_roi, self.roi_size, 1. / self.stride)\n",
    "        print(\"pooled_feat\",pooled_feat.shape)\n",
    "\n",
    "        # RCNN prediction\n",
    "        top_feat = self.top_features(pooled_feat)\n",
    "        avg_feat = self.global_avg_pool(top_feat)\n",
    "        cls_pred = self.class_predictor(avg_feat)\n",
    "        box_pred = self.box_predictor(avg_feat)\n",
    "\n",
    "        cls_pred = cls_pred.reshape((self.post_nms, self.class_num + 1))\n",
    "        # 0 是背景的概率，只需要前景的即可\n",
    "        scores = nd.softmax(cls_pred, axis=-1)[:,1:]\n",
    "        scores = scores.asnumpy()\n",
    "        print(\"scores\", scores.shape)\n",
    "        box_pred = box_pred.reshape((self.post_nms, self.class_num, 4)).transpose((1,0,2))\n",
    "        print(\"box_pred\", box_pred.shape)\n",
    "        print(\"rpn_box\", rpn_box.shape)\n",
    "        \n",
    "        # 入参/返回值是 (x,y,w,h) 格式 ，且返回值维度 (C,N,4)\n",
    "        bbox = get_realbbox(box_pred.asnumpy(), rpn_box.reshape(1,-1,4).asnumpy(), wh_max=4.42)\n",
    "        print(\"bbox\", bbox.shape)\n",
    "        # 入参/返回值都是 (xmin,ymin,xmax,ymax) 格式\n",
    "        #bbox = bbox_clip_by_img(center2corner(bbox.reshape(-1,4)), img=[800,600])\n",
    "        bbox = bbox.transpose((1,0,2))\n",
    "        print(\"bbox\", bbox.shape)\n",
    "\n",
    "\n",
    "        # 剔除 score 小于 thread 的预测\n",
    "        mask = scores > self.socre_thread\n",
    "\n",
    "        \n",
    "\n",
    "        return scores, bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FasterRcnn()\n",
    "\n",
    "# 加载参数\n",
    "net.features.load_parameters(\"features.params\")\n",
    "net.top_features.load_parameters(\"topfeatures.params\")\n",
    "#net.global_avg_pool.load_parameters(\"global_avg_pool.params\")\n",
    "net.class_predictor.load_parameters(\"class_predictor.params\")\n",
    "net.box_predictor.load_parameters(\"box_predictor.params\")\n",
    "net.rpn.load_parameters(\"rpn_conv1.params\")\n",
    "net.rpn_score.load_parameters(\"rpn_score.params\")\n",
    "net.rpn_loc.load_parameters(\"rpn_loc.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_img(imgname, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    \"\"\"图像 nominalize \n",
    "    测试的时候，transform 不需要额外的处理，只需要归一化以及将 BCWH -> \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs : string \n",
    "        待处理的图像名字\n",
    "    mean : iterable of float\n",
    "        Mean pixel values.\n",
    "    std : iterable of float\n",
    "        Standard deviations of pixel values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    网络的输入和 resize 后的图像\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    img = mx.image.imread(imgname)\n",
    "\n",
    "    # 可能只能在 800*600 时 work\n",
    "    img = mx.image.imresize(img, 800, 600)\n",
    "    orig_img = img.asnumpy().astype('uint8')\n",
    "    img = mx.nd.image.to_tensor(img)\n",
    "    img = mx.nd.image.normalize(img, mean=mean, std=std)\n",
    "    # img.expand_dims(0) 由 CHW -> BCHW\n",
    "    return img.expand_dims(0), orig_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgname = 'biking.jpg'\n",
    "x, img = preprocessing_img(imgname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, bbox = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreindex = score.argsort(axis=-1)\n",
    "scoreindex = scoreindex[:,::-1] # 逆序\n",
    "cids = scoreindex[:,0].astype(np.int32)\n",
    "print(cids)\n",
    "\n",
    "sco = []\n",
    "for i in range(len(scoreindex)):\n",
    "    sco.append(score[i,cids[i]])\n",
    "    if i == 0:\n",
    "        box = bbox[i,cids[i],:]\n",
    "    else:\n",
    "        box = np.row_stack([box, bbox[i,cids[i],:]])\n",
    "\n",
    "# cids 类别标号\n",
    "# sco 类别概率\n",
    "sco = np.array(sco)\n",
    "# box bounding box\n",
    "\n",
    "remove_ixs = np.where(sco < 0.1)\n",
    "print(remove_ixs)\n",
    "clean_cids = np.delete(cids, remove_ixs)\n",
    "clean_sco  = np.delete(sco, remove_ixs, axis=0)\n",
    "clean_box  = np.delete(box, remove_ixs, axis=0)\n",
    "clean_box = bbox_clip_by_img(center2corner(clean_box), img=[800,600])\n",
    "print(clean_cids)\n",
    "print(clean_sco)\n",
    "print(clean_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  classify_ouput(data):\n",
    "    \"\"\"将输出分类，便于分类别进行 NMS\n",
    "    data : numpy array\n",
    "    \n",
    "    输出 list \n",
    "    \"\"\"\n",
    "    # 按照类别进行排序\n",
    "    index = data[:,0].argsort()\n",
    "    data = data[index,:]\n",
    "    \n",
    "    split_index = []\n",
    "    clas = data[0,0]\n",
    "    index = 0\n",
    "    for i in range(1, len(data)):\n",
    "        index += 1\n",
    "        if clas != data[i,0]:\n",
    "            split_index.append(index)\n",
    "            clas = data[i,0]    \n",
    "\n",
    "    return np.split(data, split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coco 80 个类\n",
    "classes_name = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', \n",
    "                'train', 'truck', 'boat', 'traffic light', 'fire hydrant', \n",
    "                'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', \n",
    "                'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', \n",
    "                'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "                'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', \n",
    "                'baseball glove', 'skateboard', 'surfboard', 'tennis racket', \n",
    "                'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', \n",
    "                'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', \n",
    "                'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "                'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', \n",
    "                'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', \n",
    "                'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', \n",
    "                'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes_name[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from gluoncv import utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "ax = utils.viz.plot_bbox(img, clean_box, clean_sco,\n",
    "                         clean_cids, class_names=classes_name)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv import model_zoo\n",
    "\n",
    "net = model_zoo.get_model('faster_rcnn_resnet50_v1b_coco', pretrained=True)\n",
    "\n",
    "net.features.save_parameters(\"features.params\")\n",
    "net.top_features.save_parameters(\"topfeatures.params\")\n",
    "#net.global_avg_pool.save_parameters(\"global_avg_pool.params\")\n",
    "net.class_predictor.save_parameters(\"class_predictor.params\")\n",
    "net.box_predictor.save_parameters(\"box_predictor.params\")\n",
    "net.rpn.conv1.save_parameters(\"rpn_conv1.params\")\n",
    "net.rpn.score.save_parameters(\"rpn_score.params\")\n",
    "net.rpn.loc.save_parameters(\"rpn_loc.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
